Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]Generating train split:   4%|▍         | 1000/25000 [00:01<00:27, 860.39 examples/s]Generating train split: 100%|██████████| 25000/25000 [00:01<00:00, 20817.70 examples/s]Generating train split: 100%|██████████| 25000/25000 [00:01<00:00, 16163.56 examples/s]
Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 25000/25000 [00:00<00:00, 251226.93 examples/s]
Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]Generating unsupervised split:  54%|█████▍    | 27000/50000 [00:00<00:00, 259309.01 examples/s]Generating unsupervised split: 100%|██████████| 50000/50000 [00:00<00:00, 256067.21 examples/s]
Map:   0%|          | 0/25000 [00:00<?, ? examples/s]Map:   0%|          | 0/25000 [00:00<?, ? examples/s]
Traceback (most recent call last):
  File "/home/ziyizhan/code/LLM-attack/LLM-finetune/FPFT.py", line 30, in <module>
    tokenized_datasets = dataset.map(tokenize_function, batched=True)
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/dataset_dict.py", line 901, in map
    {
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/dataset_dict.py", line 902, in <dictcomp>
    k: dataset.map(
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/arrow_dataset.py", line 562, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/arrow_dataset.py", line 3079, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/arrow_dataset.py", line 3519, in _map_single
    for i, batch in iter_outputs(shard_iterable):
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/arrow_dataset.py", line 3469, in iter_outputs
    yield i, apply_function(example, i, offset=offset)
  File "/home/ziyizhan/code/LLM_attack_env/lib64/python3.9/site-packages/datasets/arrow_dataset.py", line 3392, in apply_function
    processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)
  File "/home/ziyizhan/code/LLM-attack/LLM-finetune/FPFT.py", line 21, in tokenize_function
    inputs = tokenizer(
NameError: name 'tokenizer' is not defined
